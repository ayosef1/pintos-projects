             +--------------------------+
             |          CS 212          |
             | PROJECT 2: USER PROGRAMS |
             |     DESIGN DOCUMENT      |
             +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Abraham Yosef <ayosef@stanford.edu>
Anthony Mensah <admensah@stanford.edu>
Gordon Martinez-Piedra <martigp@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

               ARGUMENT PASSING
               ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Size of word used, frequently when pushing to stack */
#define WORD_SIZE sizeof (void *)

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

The only difference from argument passing style of 80x86 described in
Section 3.5 of the Pintos reference is that we order the tokenized
literals in the opposite direction. This means we push words of
the command in left to right order (whereas 3.5 does it in right to left).

We implement this by tokenizing and pushing each word of the command onto
the stack, each time incrementing our argument counter. In order to tokenize
we first allocate a page to have an copyable version of the command string.
Similarly, we allocate a page to store the addresses of each word of the 
command pushed to the stack. The order of the addresses in this page are the
same as the order that they are pushed.

Next, we add the padding by looking at the current stack addres and rounding
down to the nearest word size (4 for our 32-bit x86 simulators). We then copy
each of the addresses of the arguments from the page we allocated onto the
stack. To do this in the correct order, we start from the last address we
added to the page of addresses, and iterate backwards (using the stored number
of arguments to do so). 

Finally we push argv, argc and the null return address.

Since we know that the command line length is not greater than a page itself,
once we have pushed all the arguments to the page, we then know how much more
space will have to be allocated (4 bytes for each argument, 12 bytes for return
argv, argcc and then however many padding bytes). If total bytes is greater
than the number of pages then we return false.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

The difference betwen strtok and strtok_r () is how the remaining string is
stored. strtok () reads up to the first instance of a delimiter and stores
the remainder of the string in a static buffer. strtok_r() on the other hand
requires you to provide a SAVE_PTR which is set to point at remaining part of
the string after the next delimiter.

The reason that Pintos implements strtok_r() is because it provides the same
functionality as strtok () but has thread safety. If multiple threads are using
strtok, there is a data race on the static buffer, as all the threads use
this to reference the remainder of the string that hasn't been parsed.


>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

The first advantage is security. String operations are famously unsafe and
can cause undefined behaviour. Performing the string operations involved in
command tokenization to an application (the shell) rather than in the kernel
mitigates and isolates the damage from any vulnerabilities in tokenization as
well as protecting the critical infrastructure that is the kernel.

The second advantage is a better abstraction of the kernel. The kernel is a
low level interface with the hardware that abstracts this unsafe interaction
away from applications. The shell on the other hand is an application,
one layer of abstraction above the kernel. The tokenization of a command, which
is directly passed to the shell therefore is much more alligned with the layer
of abstraction that the shell provides. Once a verified command has been parsed
then it makes sense to pass to the kernel to execute the command. The shell
can then store the remaining arguments and pass them to the kernel later as
required.

A third advantage is that it allows for the simplification of the kernel.
Having the shell parse the command allows the shell to perform the first
steps for functionalities such as redirection and pipelining (applications
that use system calls, rather than base kernel functionalities). Kernel
operations are more expensive so minimimzing time in the kernel is desirable.

                 SYSTEM CALLS
                 ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

#define CMD_LINE_MAX 128;       /* Maximum number of command line characters */
#define BUF_MAX 512;            /* Max bytes to write to console in one call */

#define MAX_FILES 128;          /* Size of the file descriptor table and 
                                   therefore limit on number of files a process
                                   can open */
#define RESERVED_FD 0           /* Reserved FD that should never allocate */
#define EXEC_FD 1               /* Reserved FD for process executable */

typedef int pid_t;              /* Process id number */

/* Coarse grain lock for filesystem access */
struct lock filesys_lock;

/* Shared child processes exit information stored in the parents list of
   children. Used to communicate child's exit status to parent. */
struct child_exit_info
    {
        tid_t tid;                              /* Child's tid. */
        int exit_status;                        /* Child's exit status. */
        struct semaphore exited;                /* Sync for waiting parent to
                                                   get exit status of child. */
        struct list_elem child_elem;            /* List element for per thread
                                                   children list. */
        int refs_cnt;                           /* Number of references */   
        struct lock refs_lock;                  /* Lock to access refs_cnt */
    };

Members added to `struct thread`:

      int next_fd;                        /* Smallest available fd. */
      int exit_status;                    /* Exit status of thread. */
      struct list children;               /* List of children's shared exit 
                                             information. */
      struct file *fdtable[MAX_FILES];    /* File Descriptor Table. */
      struct child_exit_info *exit_info;  /* Thread's exit information shared 
                                             with parent. */

/* Arguments passed into child thread in start_process. Contains
   parsed arguments for stack setup and synchronization for parent
   waiting for child load status. */
struct process_arg 
    {
        char *exec_name;                /* Name of executable. */
        char *save_ptr;                 /* Save ptr from tokenizing cmd line. */
        char *page;                     /* Page on which cmd_line stored. */
        bool loaded;                    /* Whether child load successful. */
        struct semaphore loaded_sema;   /* Ensure parent waits for child 
                                           to load. */
    };

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

File descriptors are unique within a single process. When a call is made
to open a file, the process allocates a file descriptor to the file.
Allocation happens by choosing the lowest unused file descriptor by that
process. Note that fds 0 and 1 are reserved to be given to the user so as not
to be confused with STDIN and STDOUT. On the thread side, 0 is never
used and 1 is used to store the thread's executable file. When a process closes
a file, the assocaited file descriptor is free to be used again.

This abstraction is implemented through a array of file pointers called a
file descriptor table. Each fd refers to the index in the file
descriptor  table that has the pointer to the corresponding file.

Note that a process can allocate up to 126 (128 - 2 reserved) file descriptors
and that there is not limit to the number of these that can point to the
same file.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

Our code begins by validating each of the arguments passed to read and write
sys calls following the first method as described by the spec. If validation 
fails, it immediately returns -1.

Otherwise, if the fd is STDIN or STDOUT, for read and write respectively, 
it reads from / writes to the console, returning only when successfully 
completing the entire read / write. Writes to the console are limited to 512
bytes at a time so as to interleave with other outputs to the console.

Otherwise, the code gets the relevant file pointer from the thread's fd
table, acquires the filesystem lock and performs the relevant action with the
relevant filesys call. Once complete, it releases the filesystem lock and
returns bytes read / written.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

We assume that the `file` that is to be written to has been opened already
and that we consider the number of inspections of the page table during a
call to write after the stack pointer has been validated. 

Irrespective of the number of bytes in the buffer, we first need to check that
each byte of the args is in valid user space. This requires at minimum 3
inspections if all args are in a single page. However, if one  argument spans
two pages then this will require 2 inspections for this arg and 4 in total.

Next we check every byte in the buffer is in valid user space. We do this by
verifying that each page that the buffer bytes occupy is valid and designated
to the user. Since each page is exactly 4kB, both 4kB data dn 2B data can span
one or two pages. Therefore we have a minimum for 1 inspection and a maximum
of 2 for the buffer bytes.

Therefore in total for both 2B and 4kB of user data we have a mimimum of 
3+1 = 4 inspections and a maximum of 4+2 = 6 inspections. As a note, if the
first argument spanned two pages and the second page was invalid, there would
only be 2 inspections.

Rooms for improvement can really only come by reducing our checks for the args.
Instead of checking each argument individually we could check whether they
collectively occupy valid user space. Since arguments theoretically can occupy
at most 12 bytes (3 args), this would means argument checking would at require
1-2 checks depending on whether they span several pages (reducing number of
checks by 2). We did not implement this because it complicates the interface
for parsing string arguments whose length is unknown.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

The wait system call looks through its list the shared children exit 
information to see if the TID matches any of them. If it doesn't it returns an
error, otherwise it blocks on the semaphore inside this struct waiting for the,
child to signal that it is ready to exit. It then collects the child's exit 
status and signal the child that it can exit.

On the other side, when a process exits, it sets its exit status in its shared
exit information signals to corresponding semaphore to wake up the parent if 
its waiting.

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

Error handling
__________________

A number of these issues are common across different syscalls and so we
abstract them away by making calls to helper functions. One example is a set
of helper functions that validate and read values of the stack such as
`get_arg_int`. `get_arg_int` takes the stack pointer (pre-validated) and 
returns the parsed int. If there is an issue with memory it will call exit(-1)
internally.

`get_arg_int` is very generalizable. It is used for syscall numbers,
file descriptors and buffer sizes. We have a similar helpers for buffers (where
we know the size) and strings (where we don't know the size). Not knowing the
length of the string makes this a particularly difficult task so abstracting
this into its own function clears up a lot of scope for obfuscation. For both
buffers and strings, these functions return NULL for a non fatal issue and exit
for a fatal error. The NULL return makes it clear in the control flow what
went wrong.

There are also a number of checks that are not generalizable and must take
place inside each of the system call handlers. For example, control flow based
on the fd passed to `write` having to find the next available fd after
allocating an fd in a call to `open`. To reduce confusion in these sections we
provide comments to sections that are not obvious and secondly favour clear,
readable control flow over fewer lines of code.

Freeing resources after error:
______________________________

To ensure freeing of resouces after an error, we ensure all termination passes
through the same cleanup function (namely `process_exit` which is accessed
through `thread_exit`). Here all locks are released andfiles closed. Described
more in detail in B8, the `refs_count` and corresponding `refs_lock` in the
shared data structure `child_exit_info` means that the last process to exit
will free the memory associated with the shared DS, irrespective whether from 
error or not. Other than the temporary buffer used for tokenization, no other
temporary buffers are allocated. Any pages allocated by the user process are
freed by the call to `pagedir_destory`.

---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

We added a a semaphore `loaded_sema` to struct thread. Each parents when
making a call to exec (and therefore process_execute) has to wait for the
child to signal them using this semaphore that they have completed loading.
Before the child signals the parent, it sets its member `loaded`. Therefore the
parent can check the `loaded` member once it has been signaled to decided how
to return from exec.

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

There are two key pieces of synchronization between parent P and child C.
Both of these exists in a shared data structure `child_exit_info` that is freed
by whichever processes exits first. The data structure is stored in the 
`children` list in the parent, and the child stores a pointer to it. This DS
allows for the child to share its exit_status to the parent without
concern about which exited first.

The first sync is a semaphore in the shared child exit information. This is 
used for sync between a waiting parent and its child. This sema is signaled 
while the child is exiting, after it sets the exit status in the shared child
data structure. Only after this has been signaled does the parent
read the exit status and return from wait. If the parent calls wait first, it
blocks until the child signals. If the child exits before the call, the parent
doens't block when it calls `sema_down` and can just return immediately.

The second piece of synchronization is a lock that protects a ref count. The
ref count, as the name suggests, is the number of references to the shared data
structure. This acts as a proxy for both the parent and child to determine
whether the other has exited or not. Initialized to 2, both child and parent
decrement the ref count when they stop using the shared data structure. For a
child this is when it exits. For a parent, this is after it has been signaled
by its child in a call ot wait or when it terminates without waiting. In all
these cases, the process, decrements the ref count and reads its value. After
decrementing if ref count is 1, this means that the other process is still alive
and it needs to special action. If it is 0, this means that the other process
has reached the decrement first and so it is responsible for freeing the shared
data structure. This ref count allows for the shared data sturcture as it
ensures the strucutre is freed no matter how child and parent exit and it what
order.

The only edge cases there could be is an interleaving of exits between child
and non waiting parent. To deal with this instance, we have a simple policy
that the thread that decremented the ref count to 0 must free the shared
child exit information data structure.

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

We decided to take the first approach to access to user memory that invovled
checking whether the memory was valid before accessing it. This is definitely
the less efficient approach than allowing the specialized MMU to handle invalid
accesses and cause a page fault. However, we chose the approach because of its
simplicity. Specifically, it is very clear when reading our implementation
how and where memory access is validated.  Conversely, the page fault approach 
is mostly done under the hood, the OS only deal with the internal interrupt
that results from an illegal access.

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

The advantages of the design is in its ease of performing file operations. 
The file descriptor table as a static array of file pointers means that the
file descriptor can be the index into this array to access the corresponding
file pointer. Similarly finding the next free file descriptor is O(n) operation. 
static array of file pointers makes finding the file corresponding to a file
descriptor and O(1) operation. Similarly, finding the next free file descriptor
is an O(n) operation. It also has advantages for processes that are opening
and closing files frequently, there isn't any overhead for allocating and
deallocating fds e.g. creating list elements and removing from a list.

The key disadvantage is in staticness and expensive memory. The table occupies
128 * pointer size of bytes. However, user processes could vary greatly and 
this implementation risks allocating too much space. In the less common case of
more than 128 file descriptors, it does not having the flexibility to accomodate
for them. A final disadvantage is the confusing 0th and 1st entry in the file
descriptor. Since these can't be allocated (reserved for STDIN and STDOUT),
the second is repurposed to store a process' executable file pointer. While
making use of unused space, this is a hacky approach and might not be clear
to a third party reading the codebase.

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

We maintained a 1 to 1 mapping of the two. Again this was for simplicity sake
and to reflect the fact that every user processes corresponds to a single
thread.

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
