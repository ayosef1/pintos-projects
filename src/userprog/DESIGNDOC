             +--------------------------+
             |          CS 212          |
             | PROJECT 2: USER PROGRAMS |
             |     DESIGN DOCUMENT      |
             +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Abraham Yosef <ayosef@stanford.edu>
Anthony Mensah <admensah@stanford.edu>
Gordon Martinez-Piedra <martigp@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

               ARGUMENT PASSING
               ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Size of word used, frequently when pushing to stack */
#define WORD_SIZE sizeof (void *)

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

The only difference from argument passing style of 80x86 described in
Section 3.5 of the Pintos reference is that we order the tokenized
literals in the opposite direction. This means we push words of
the command in left to right order (whereas 3.5 does it in right to left).

We implement this by tokenizing and pushing each word of the command onto
the stack, each time incrementing our argument counter. In order to tokenize
we first allocate a page to have an copyable version of the command string.
Similarly, we allocate a page to store the addresses of each word of the 
command pushed to the stack. The order of the addresses in this page are the
same as the order that they are pushed.

Next, we add the padding by looking at the current stack addres and rounding
down to the nearest word size (4 for our 32-bit x86 simulators). We then copy
each of the addresses of the arguments from the page we allocated onto the
stack. To do this in the correct order, we start from the last address we
added to the page of addresses, and iterate backwards (using the stored number
of arguments to do so). 

Finally we push argv, argc and the null return address.

Since we know that the command line length is not greater than a page itself,
once we have pushed all the arguments to the page, we then know how much more
space will have to be allocated (4 bytes for each argument, 12 bytes for return
argv, argcc and then however many padding bytes). If total bytes is greater
than the number of pages then we return false.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

The difference betwen strtok and strtok_r () is how the remaining string is
stored. strtok () reads up to the first instance of a delimiter and stores
the remainder of the string in a static buffer. strtok_r() on the other hand
requires you to provide a SAVE_PTR which is set to point at remaining part of
the string after the next delimiter.

The reason that Pintos implements strtok_r() is because it provides the same
functionality as strtok () but has thread safety. If multiple threads are using
strtok, there is a data race on the static buffer, as all the threads use
this to reference the remainder of the string that hasn't been parsed.


>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

The first advantage is security. String operations are famously unsafe and
can cause undefined behaviour. Performing the string operations involved in
command tokenization to an application (the shell) rather than in the kernel
mitigates and isolates the damage from any vulnerabilities in tokenization as
well as protecting the critical infrastructure that is the kernel.

The second advantage is a better abstraction of the kernel. The kernel is a
low level interface with the hardware that abstracts this unsafe interaction
away from applications. The shell on the other hand is an application,
one layer of abstraction above the kernel. The tokenization of a command, which
is directly passed to the shell therefore is much more alligned with the layer
of abstraction that the shell provides. Once a verified command has been parsed
then it makes sense to pass to the kernel to execute the command. The shell
can then store the remaining arguments and pass them to the kernel later as
required.

A third advantage is that it allows for the simplification of the kernel.
Having the shell parse the command allows the shell to perform the first
steps for functionalities such as redirection and pipelining (applications
that use system calls, rather than base kernel functionalities). Kernel
operations are more expensive so minimimzing time in the kernel is desirable.

                 SYSTEM CALLS
                 ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

#define CMD_LINE_MAX 128;       /* Maximum number of command line characters */
#define BUF_MAX 512;            /* Max bytes to write to console in one call */

#define MAX_FILES 128;          /* Size of the file descriptor table and 
                                   therefore limit on number of files a process
                                   can open */
#define RESERVED_FD 0           /* Reserved FD that should never allocate */
#define EXEC_FD 1               /* Reserved FD for process executable */

typedef int pid_t;              /* Process id number */

/* Coarse grain lock for filesystem access */
struct lock filesys_lock;

Members added to struct thread:

    int next_fd;                                /* Smallest available fd. */
    int exit_status;                            /* Exit status of thread. */
    bool loaded;                                /* Thread loaded executable
                                                   and stack successfully */
    struct list children;                       /* List of child structs. */
    struct list_elem children_elem;             /* List element for per thread
                                                   children list */
    struct semaphore exit_status_ready;         /* Sync for waiting parent to
                                                   get exit status of child */
    struct semaphore exit_status_received;      /* Sync for child to exit after
                                                   parent gets exit status */

    struct semaphore loaded_sema;               /* Sync for child loading and
                                                   returning child tid from
                                                   exec syscall */
   struct file *fdtable[MAX_FILES];             /* File Descriptor Table. */

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

File descriptors are unique within a single process. When a call is made
to open a file, the process allocates a file descriptor to the file.
Allocation happens by choosing the lowest unused file descriptor by that
process. Note that fds 0 and 1 are reserved to be given to the user so as not
to be confused with STDIN and STDOUT. On the thread side, 0 is never
used and 1 is used to store the thread's executable file. When a process closes
a file, the assocaited file descriptor is free to be used again.

This abstraction is implemented through a array of file pointers called a
file descriptor table. Each fd refers to the index in the file
descriptor  table that has the pointer to the corresponding file.

Note that a process can allocate up to 126 (128 - 2 reserved) file descriptors
and that there is not limit to the number of these that can point to the
same file.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

Our code begins by validating each of the arguments passed to read and write
sys calls following the first method as described by the spec. If validation 
fails, it immediately returns -1.

Otherwise, if the fd is STDIN or STDOUT, for read and write respectively, 
it reads from / writes to the console, returning only when successfully 
completing the entire read / write. Writes to the console are limited to 512
bytes at a time so as to interleave with other outputs to the console.

Otherwise, the code gets the relevant file pointer from the thread's fd
table, acquires the filesystem lock and performs the relevant action with the
relevant filesys call. Once complete, it releases the filesystem lock and
returns bytes read / written.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

We assume that the `file` that is to be written to has been opened already
and that we consider the number of inspections of the page table during a
call to write after the stack pointer has been validated. 

Irrespective of the number of bytes in the buffer, we first need to check that
each byte of the args is in valid user space. This requires at minimum 3
inspections if all args are in a single page. However, if one  argument spans
two pages then this will require 2 inspections for this arg and 4 in total.

Next we check every byte in the buffer is in valid user space. We do this by
verifying that each page that the buffer bytes occupy is valid and designated
to the user. Since each page is exactly 4kB, both 4kB data dn 2B data can span
one or two pages. Therefore we have a minimum for 1 inspection and a maximum
of 2 for the buffer bytes.

Therefore in total for both 2B and 4kB of user data we have a mimimum of 
3+1 = 4 inspections and a maximum of 4+2 = 6 inspections. As a note, if the
first argument spanned two pages and the second page was invalid, there would
only be 2 inspections.

Rooms for improvement can really only come by reducing our checks for the args.
Instead of checking each argument individually we could check whether they
collectively occupy valid user space. Since arguments theoretically can occupy
at most 12 bytes (3 args), this would means argument checking would at require
1-2 checks depending on whether they span several pages (reducing number of
checks by 2). We did not implement this because it complicates the interface
for parsing string arguments whose length is unknown.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

The wait system looks through its list of children to see if the TID matches
any of them. If it doesn't it returns an error (-1), otherwise it blocks
on a semaphore, waiting for the child to signal that it is ready to exit.
It then collects the child's exit status and signal the child that it can exit.

On the other side, all paths to processes termination result with a call to
process_exit. In this function the process frees all its resources, such as
locks, files and signals its about to be orphaned children that they can exit. 
Once the child has completed this the child signals to the parent it is ready
to exit. At this point it will have set its exit status. Once the parent
signals back that it has received the exit status, it completes termination.

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

A number of these issues are common across different syscalls and so we
abstract them away by making calls to helper functions. One example is a set
of helper functions that validate and read values of the stack. One example is
`get_arg_int` that takes the stack pointer (pre-validated) and returns the
parsed int. If there is an issue with memory it will call exit(-1) internally.
`get_arg_int` is very generalizable, used for syscall numbers, file descriptors
and buffer sizes. We have a similar helpers for buffers (where we know the
size) and strings (where we don't know the size).

All termination, both from errors and completion passes through the function
`thread_exit` and therefore `process_exit`. All cleanup occurs in process exit
as described earlier - release locks, signal soon to be orphaned children they
don't need to block before exiting and closing all files. All resources that
the process itself allocated is freed by the call to pagedir_destroy. In
addition to this, any temporary buffers such as the one used to assist
tokenizing the command line are freed  


---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

We added a a semaphore `loaded_sema` to struct thread. Each parents when
making a call to exec (and therefore process_execute) has to wait for the
child to signal them using this semaphore that they have completed loading.
Before the child signals the parent, it sets its member `loaded`. Therefore the
parent can check the `loaded` member once it has been signaled to decided how
to return from exec.

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

Case 1 ( wait(C) before C exits):
In this case, the parent waits to be signaled by the child through the
`wait_for_child` semaphore. This semaphore is signalled once the child
completes their cleanup as described in B5. Since it is a semaphore the
parent is blocking until they receive the signal.

Case 2( wait(C) after C exits ):
After C signals to the parent in the manner described above, C waits on P
to signal it back that it has successfully extracted its exit status. This
is done through the `wait_for_parent` semaphore.

All cleanup is done with a call to thread_exit since every path to a thread
exiting / terminating go through this path. Thread exit then calls process_exit
which is reponsible for all cleanup. In process_exit, each thread closes each 
of the files in its file descriptor table, releases all the locks it currently
holds (including the filesystem lock) and finally signals each of its 
children's `wait_for_parent` semaphores. This means in the case that the parent
exits without waiting, each of the orphaned children can exit freely instead
of waiting on this semaphore.

If P terminates without waiting, during its cleanup process it signals the
`wait_for_parent` semaphore, meaning that once an orphaned child exits it will
not wait for a signal from the parent, it just becomes free to exit.


---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
